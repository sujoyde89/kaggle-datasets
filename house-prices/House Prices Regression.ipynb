{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This kernel contains the solution codes for House Prices: Advanced Regression Techniques competion of www.kaggle.com website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges us to predict the final price of each home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization for all the variables to derive necessary information has been done in house prices visualization file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd # package for high-performance, easy-to-use data structures and data analysis\n",
    "import numpy as np # fundamental package for scientific computing with Python\n",
    "\n",
    "# Supress unnecessary warnings so that presentation looks clean\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Print all rows and columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will  read the train and test datasets using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\") # reading the train dataset\n",
    "test = pd.read_csv(\"test.csv\") # reading the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove some outliers from the train dataset. The outliers that would be removed was decided in the visualization file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train dataset before removing outliers is 1460\n",
      "Number of rows in train dataset after removing outliers is 1453\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of rows in train dataset before removing outliers is \" + str(train.shape[0]))\n",
    "# The visualization for the three variables has been done in the House Prices Visualization file. \n",
    "# The outliers have been identified from the visualization that we had done\n",
    "train = train[train.GrLivArea < 4000] # Removing the outliers for Grade living area\n",
    "train = train[train.TotalBsmtSF < 6000] # Removing the outliers for Total Basement Sq. footage\n",
    "train = train[train.LotArea < 150000] # Removing the outliers for Total Lot Area\n",
    "print (\"Number of rows in train dataset after removing outliers is \" + str(train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "\n",
       "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "0         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "1         Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
       "\n",
       "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       Norm     1Fam     2Story            7            5       2003   \n",
       "1       Norm     1Fam     1Story            6            8       1976   \n",
       "\n",
       "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "0          2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "1          1976     Gable  CompShg     MetalSd     MetalSd       None   \n",
       "\n",
       "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
       "0       196.0        Gd        TA      PConc       Gd       TA           No   \n",
       "1         0.0        TA        TA     CBlock       Gd       TA           Gd   \n",
       "\n",
       "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          GLQ         706          Unf           0        150          856   \n",
       "1          ALQ         978          Unf           0        284         1262   \n",
       "\n",
       "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
       "0    GasA        Ex          Y      SBrkr       856       854             0   \n",
       "1    GasA        Ex          Y      SBrkr      1262         0             0   \n",
       "\n",
       "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0       1710             1             0         2         1             3   \n",
       "1       1262             0             1         2         0             3   \n",
       "\n",
       "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
       "0             1          Gd             8        Typ           0         NaN   \n",
       "1             1          TA             6        Typ           1          TA   \n",
       "\n",
       "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
       "0     Attchd       2003.0          RFn           2         548         TA   \n",
       "1     Attchd       1976.0          RFn           2         460         TA   \n",
       "\n",
       "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0         TA          Y           0           61              0          0   \n",
       "1         TA          Y         298            0              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea PoolQC Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
       "0            0         0    NaN   NaN         NaN        0       2    2008   \n",
       "1            0         0    NaN   NaN         NaN        0       5    2007   \n",
       "\n",
       "  SaleType SaleCondition  SalePrice  \n",
       "0       WD        Normal     208500  \n",
       "1       WD        Normal     181500  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets print the head of train to get an idea\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Rec</td>\n",
       "      <td>468.0</td>\n",
       "      <td>LwQ</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>5</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>108.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>923.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>393</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
       "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "0         Lvl    AllPub    Inside       Gtl        NAmes      Feedr   \n",
       "1         Lvl    AllPub    Corner       Gtl        NAmes       Norm   \n",
       "\n",
       "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       Norm     1Fam     1Story            5            6       1961   \n",
       "1       Norm     1Fam     1Story            6            6       1958   \n",
       "\n",
       "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "0          1961     Gable  CompShg     VinylSd     VinylSd       None   \n",
       "1          1958       Hip  CompShg     Wd Sdng     Wd Sdng    BrkFace   \n",
       "\n",
       "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
       "0         0.0        TA        TA     CBlock       TA       TA           No   \n",
       "1       108.0        TA        TA     CBlock       TA       TA           No   \n",
       "\n",
       "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          Rec       468.0          LwQ       144.0      270.0        882.0   \n",
       "1          ALQ       923.0          Unf         0.0      406.0       1329.0   \n",
       "\n",
       "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
       "0    GasA        TA          Y      SBrkr       896         0             0   \n",
       "1    GasA        TA          Y      SBrkr      1329         0             0   \n",
       "\n",
       "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0        896           0.0           0.0         1         0             2   \n",
       "1       1329           0.0           0.0         1         1             3   \n",
       "\n",
       "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
       "0             1          TA             5        Typ           0         NaN   \n",
       "1             1          Gd             6        Typ           0         NaN   \n",
       "\n",
       "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
       "0     Attchd       1961.0          Unf         1.0       730.0         TA   \n",
       "1     Attchd       1958.0          Unf         1.0       312.0         TA   \n",
       "\n",
       "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0         TA          Y         140            0              0          0   \n",
       "1         TA          Y         393           36              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea PoolQC  Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
       "0          120         0    NaN  MnPrv         NaN        0       6    2010   \n",
       "1            0         0    NaN    NaN        Gar2    12500       6    2010   \n",
       "\n",
       "  SaleType SaleCondition  \n",
       "0       WD        Normal  \n",
       "1       WD        Normal  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also print the head of test\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets store the target variable which is SalePrice in a seperate series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = train[\"SalePrice\"]\n",
    "# Log transforming the target as per the requirement in the competition for measuring the root mean squared value\n",
    "target_log = np.log1p(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets store the feature variables in the train dataframe as the target variable has already been stored in a seperate series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train[train.columns.values[:-1]] # Taking the predictors in the train dataframe as train dataset\n",
    "train = train.drop(['Id'], axis  = 1) # Dropping the Id variable as it would not be of any much help in predicting the target values\n",
    "test_Ids = test.Id #Storing the test ids in a seperate variable for later prediction\n",
    "test = test.drop(['Id'], axis  = 1) # Dropping the Id variable as it would not be of any much help for predicting the target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# joining the train and test variables for preventing multiple operations on train and test seperately\n",
    "df_original = train.append(test, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning 4\n",
      "LotFrontage 484\n",
      "Alley 2714\n",
      "Utilities 2\n",
      "Exterior1st 1\n",
      "Exterior2nd 1\n",
      "MasVnrType 24\n",
      "MasVnrArea 23\n",
      "BsmtQual 81\n",
      "BsmtCond 82\n",
      "BsmtExposure 82\n",
      "BsmtFinType1 79\n",
      "BsmtFinSF1 1\n",
      "BsmtFinType2 80\n",
      "BsmtFinSF2 1\n",
      "BsmtUnfSF 1\n",
      "TotalBsmtSF 1\n",
      "Electrical 1\n",
      "BsmtFullBath 2\n",
      "BsmtHalfBath 2\n",
      "KitchenQual 1\n",
      "Functional 2\n",
      "FireplaceQu 1420\n",
      "GarageType 157\n",
      "GarageYrBlt 159\n",
      "GarageFinish 159\n",
      "GarageCars 1\n",
      "GarageArea 1\n",
      "GarageQual 159\n",
      "GarageCond 159\n",
      "PoolQC 2904\n",
      "Fence 2342\n",
      "MiscFeature 2809\n",
      "SaleType 1\n"
     ]
    }
   ],
   "source": [
    "# let us find the features which have missing values\n",
    "for col in df_original.columns.values:\n",
    "    if np.sum(df_original[col].isnull())>0:\n",
    "        value = np.sum(df_original[col].isnull())\n",
    "        print(col,value) # printing the column names along with the missing values related to the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As per the descriptions given about the data, below are the variables where NA means the feature is not present in a house\n",
    "# So we are going to fill the NA values with 'none'\n",
    "cols = ['Alley','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','FireplaceQu','GarageType',\n",
    "       'GarageFinish','GarageQual','GarageCond','Fence','MiscFeature']\n",
    "for col in cols:\n",
    "    df_original[col] = df_original[col].fillna('none') # filling the na values with none value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pool is only present in 10 samples out of 2919 samples so dropping PoolArea and PoolQC features from the dataframe\n",
    "df_original = df_original.drop(['PoolArea','PoolQC'], axis=1) # dropping the pool features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill the missing value of lot frontage with median\n",
    "df_original['LotFrontage'] = df_original['LotFrontage'].fillna(df_original['LotFrontage'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There are several categorical variables where there are missing values denoted as NA\n",
    "# We will fill those missing values of categorical variables with the most frequent values\n",
    "cols = ['MSZoning','Utilities','Exterior1st','Exterior2nd','MasVnrType',\n",
    "        'Electrical','BsmtFullBath','BsmtHalfBath','KitchenQual','Functional','SaleType']\n",
    "for col in cols:\n",
    "    df_original[col] = df_original[col].fillna(df_original[col].value_counts().index[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to map the below variabes as per our understanding, interpretation and also the visualization that we have done earlier in the house prices visualization file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature MSSubClass is not a continuous variable as per the description so decided to change it to a categorical variable\n",
    "df_original['MSSubClass'] = df_original['MSSubClass'].map({20:'S20',30:'S30',40:'S40',45:'S45',50:'S50',60:'S60',\n",
    "                                                           70:'S70',75:'S75',80:'S80',85:'S85',90:'S90',120:'S120',\n",
    "                                                           150:'S150',160:'S160',180:'S180',190:'S190'})\n",
    "\n",
    "# For feature MSZoning decided to club the Residential Low Density Park(RP) and Residential Medium Density(RM). Refer to\n",
    "# visualization of this feature in the House Prices Visualization file\n",
    "df_original['MSZoning'] = df_original['MSZoning'].map({'RL':0,'RM':1,'RP':1,'RH':2,'I':3,'FV':4,'C (all)':5,'A':6}).astype(object)\n",
    "\n",
    "# For feature LotShape decided to club Irregular lot shapes(IRs) together as per the data description\n",
    "df_original['LotShape'] = df_original['LotShape'].map({'IR1':0,'IR2':0,'IR3':0,'Reg':1}).astype(object)\n",
    "\n",
    "# For feature LotConfig decided to club FR2(Frontage on 2 sides of property) and FR3(Frontage on 3 sides of property) together\n",
    "df_original['LotConfig'] = df_original['LotConfig'].map({'Inside':0,'Corner':1,'CulDSac':2,'FR2':3,'FR3':3}).astype(object)\n",
    "\n",
    "# Made the house style variable into a continuous variable according to the storeys available and whether it is furnished or not\n",
    "df_original['HouseStyle'] = df_original['HouseStyle'].map({'1Story':1,'2Story':2,'1.5Fin':1.5,'SLvl':2,\n",
    "                                                           'SFoyer':2,'1.5Unf':1.25,'2.5Unf':2.25,'2.5Fin':2.5})\n",
    "\n",
    "# Decided to club a few types of Exterior1st variable based on the visualization in the House Prices Visualization file and also\n",
    "# very less number of some types available in the dataset\n",
    "df_original['Exterior1st'] = df_original['Exterior1st'].map({'VinylSd':0,\n",
    "                                                             'HdBoard':1,'MetalSd':1,'Wd Sdng':1,\n",
    "                                                             'Plywood':2,\n",
    "                                                             'CemntBd':3,\n",
    "                                                             'BrkFace':4,'WdShing':4,'Stucco':4,'AsbShng':4,'Stone':4,\n",
    "                                                             'BrkComm':4,'AsphShn':4,'CBlock':4,'ImStucc':4}).astype(object)\n",
    "\n",
    "# Decided to club a few types of Exterior1st variable based on the visualization in the House Prices Visualization file and also\n",
    "# very less number of some types available in the dataset\n",
    "df_original['Exterior2nd'] = df_original['Exterior2nd'].map({'VinylSd':0,\n",
    "                                                             'HdBoard':1,'MetalSd':1,'Wd Sdng':1,\n",
    "                                                             'Plywood':1,'WdShing':1,'Wd Shng':1,'CmentBd':2,\n",
    "                                                             'Stucco':3,'BrkFace':3,'AsbShng':3,'ImStucc':3,\n",
    "                                                             'Brk Cmn':3,'Stone':3,'AsphShn':3,'CBlock':3,'Other':3}).astype(object)\n",
    "\n",
    "# Decided to club a few types of MasVnr variable based on the description of the data. \n",
    "# BrkFace and BrkCmn belongs to brick category\n",
    "df_original['MasVnrType'] = df_original['MasVnrType'].map({'None':0,'CBlock':1,'BrkFace':2,'BrkCmn':2,'Stone':3}).astype(object)\n",
    "\n",
    "# Decided to club a few types of Foundation variable because of very less number of some types available in the dataset\n",
    "df_original['Foundation'] = df_original['Foundation'].map({'PConc':0,'CBlock':1,'BrkTil':2,'Slab':3,'Stone':3,'Wood':3}).astype(object)\n",
    "\n",
    "# Nothing much fancy with BsmtExposure, BsmtFinType1, BsmtFinType2, GarageType, GarageFinish. Just turned the non numerical ones.\n",
    "# Could have left the features as they were.\n",
    "df_original['BsmtExposure'] = df_original['BsmtExposure'].map({'Gd':4,'Av':3,'Mn':2,'No':1,'none':0}).astype(object)\n",
    "df_original['BsmtFinType1'] = df_original['BsmtFinType1'].map({'GLQ':6,'ALQ':5,'BLQ':3,'Rec':3,'LwQ':2,'Unf':1,'none':0}).astype(object)\n",
    "df_original['BsmtFinType2'] = df_original['BsmtFinType2'].map({'none':0,'Unf':1,'LwQ':2,'Rec':2,'BLQ':2,'ALQ':3,'GLQ':4}).astype(object)\n",
    "df_original['GarageType'] = df_original['GarageType'].map({'none':0,'Detchd':1,'CarPort':2,'BuiltIn':3,\n",
    "                                                           'Basment':4,'Attchd':5,'2Types':6}).astype(object)\n",
    "df_original['GarageFinish'] = df_original['GarageFinish'].map({'none':0,'Unf':1,'RFn':2,'Fin':3}).astype(object)\n",
    "\n",
    "# For heating variable tried to club all the types with less number of occurences in the dataset\n",
    "df_original['Heating'] = df_original['Heating'].map({'GasA':0,'GasW':1,'Grav':1,'Wall':1,'OthW':1,'Floor':1}).astype(object)\n",
    "\n",
    "# Changed the month variable into a categorical variable\n",
    "df_original['MoSold'] = df_original['MoSold'].replace({1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr',\n",
    "                                                       5:'May', 6:'Jun', 7:'Jul', 8:'Aug',\n",
    "                                                       9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'})\n",
    "\n",
    "# Clubbed the various types of sale type variables based on the description given about the data\n",
    "df_original['SaleType'] = df_original['SaleType'].map({'Oth':1,\n",
    "                                                       'ConLD':2,'ConLI':2,'ConLw':2,'Con':2,\n",
    "                                                       'COD':3,\n",
    "                                                       'New':4,\n",
    "                                                       'WD':5,'CWD':5,'VWD':5}).astype(object)\n",
    "\n",
    "# Clubbed the various types of sale condition variables based on the description given about the data\n",
    "df_original['SaleCondition'] = df_original['SaleCondition'].map({'Normal':0,'Partial':1,'Abnorml':2,\n",
    "                                                                 'Family':0,'Alloca':0,'AdjLand':0}).astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the Quality and Condition variables into continuous variables as they are categorical variables but ordinal in nature. I have always experienced transforming ordinal into continuous variables always help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_original['ExterQual'] = df_original['ExterQual'].map({'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1})\n",
    "df_original['ExterCond'] = df_original['ExterCond'].map({'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1})\n",
    "\n",
    "df_original['BsmtQual'] = df_original['BsmtQual'].map({'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,'none':0})\n",
    "df_original['BsmtCond'] = df_original['BsmtCond'].map({'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,'none':0})\n",
    "\n",
    "\n",
    "df_original['GarageQual'] = df_original['GarageQual'].map({'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,'none':0})\n",
    "df_original['GarageCond'] = df_original['GarageCond'].map({'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,'none':0})\n",
    "\n",
    "df_original['HeatingQC'] = df_original['HeatingQC'].map({'Ex':5,'TA':3,'Gd':4,'Fa':2,'Po':1})\n",
    "df_original['KitchenQual'] = df_original['KitchenQual'].map({'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1})\n",
    "df_original['FireplaceQu'] = df_original['FireplaceQu'].map({'none':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For the below variables, the idea is that if a certain feature is not present then a related feature would be o. Otherwise the missing value for that related feature was filled with the most frequent value. \n",
    "\n",
    "2. Suppose if garage is not present then garage area would be 0. But if a garage is present and somehow the area is missing, the missing value in this case would be filled with the most frequent value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in range(0,df_original.shape[0]):\n",
    "    if np.isnan(df_original['GarageCars'][row]):\n",
    "        if df_original['GarageType'][row] == 0:\n",
    "            df_original['GarageCars'][row] = 0\n",
    "        else:\n",
    "            df_original['GarageCars'][row] = df_original['GarageCars'].value_counts().index[0]\n",
    "            \n",
    "    if np.isnan(df_original['GarageArea'][row]):\n",
    "        if df_original['GarageType'][row] == 0:\n",
    "            df_original['GarageArea'][row] = 0\n",
    "        else:\n",
    "            df_original['GarageArea'][row] = df_original['GarageArea'].value_counts().index[0]\n",
    "            \n",
    "    if np.isnan(df_original['GarageYrBlt'][row]):\n",
    "        if df_original['GarageType'][row] == 0:\n",
    "            df_original['GarageYrBlt'][row] = df_original['YrSold'][row]\n",
    "        else:\n",
    "            df_original['GarageYrBlt'][row] = df_original['GarageYrBlt'].value_counts().index[0]\n",
    "            \n",
    "    if np.isnan(df_original['BsmtFinSF1'][row]):\n",
    "        if df_original['BsmtQual'][row] == 0:\n",
    "            df_original['BsmtFinSF1'][row] = 0\n",
    "        else:\n",
    "            df_original['BsmtFinSF1'][row] = df_original['BsmtFinSF1'].median()\n",
    "            \n",
    "    if np.isnan(df_original['BsmtFinSF2'][row]):\n",
    "        if df_original['BsmtQual'][row] == 0:\n",
    "            df_original['BsmtFinSF2'][row] = 0\n",
    "        else:\n",
    "            df_original['BsmtFinSF2'][row] = df_original['BsmtFinSF2'].median()\n",
    "            \n",
    "    if np.isnan(df_original['BsmtUnfSF'][row]):\n",
    "        if df_original['BsmtQual'][row] == 0:\n",
    "            df_original['BsmtUnfSF'][row] = 0\n",
    "        else:\n",
    "            df_original['BsmtUnfSF'][row] = df_original['BsmtUnfSF'].median()\n",
    "            \n",
    "    if np.isnan(df_original['TotalBsmtSF'][row]):\n",
    "        df_original['TotalBsmtSF'][row] = df_original['BsmtFinSF1'][row] + df_original['BsmtFinSF2'][row] + df_original['BsmtUnfSF'][row]\n",
    "        \n",
    "    if np.isnan(df_original['MasVnrArea'][row]):\n",
    "        if df_original['MasVnrType'][row] == 0:\n",
    "            df_original['MasVnrArea'][row] = 0\n",
    "        else:\n",
    "            df_original['MasVnrArea'][row] = df_original['MasVnrArea'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_original['Age'] = df_original['YrSold'] - df_original['YearBuilt']\n",
    "df_original['Garage_Age'] = df_original['YrSold'] - df_original['GarageYrBlt']\n",
    "df_original['Remodel_Age'] = df_original['YrSold'] - df_original['YearRemodAdd']\n",
    "df_original['Porch_Area'] = df_original['OpenPorchSF'] + df_original['ScreenPorch'] + df_original['3SsnPorch'] + df_original['EnclosedPorch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The neighborhood class was divided into three classes Average, Good, Excellent based on the feature's visualization with the house prices done in the House Prices Visualization File.\n",
    "\n",
    "2. For Alley, Basement, Basement Finish Type 1 and Type 2, Fireplaces, Garage, Fence, Miscellaneous features, another feature was engineered for each of them to denote whether they are present or not\n",
    "\n",
    "3. Season feature was engineered for which months the price tend to be a bit higher. It was visualized in the House Prices visualization file\n",
    "\n",
    "4. Newer dwelling was also engineered for relatively newer houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#neighborhood class\n",
    "df_original['Neighborhood_class'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['Neighborhood_class'].loc[df_original['Neighborhood_class'] == 0] = 'Average'\n",
    "df_original['Neighborhood_class'].loc[df_original['Neighborhood'] == 'Veenker'] = 'Good'\n",
    "df_original['Neighborhood_class'].loc[df_original['Neighborhood'] == 'NoRidge'] = 'Excellent'\n",
    "df_original['Neighborhood_class'].loc[df_original['Neighborhood'] == 'Somerst'] = 'Good'\n",
    "df_original['Neighborhood_class'].loc[df_original['Neighborhood'] == 'NridgHt'] = 'Excellent'\n",
    "df_original['Neighborhood_class'].loc[df_original['Neighborhood'] == 'Timber'] = 'Good'\n",
    "df_original['Neighborhood_class'].loc[df_original['Neighborhood'] == 'StoneBr'] = 'Excellent'\n",
    "df_original['Neighborhood_class'] = df_original['Neighborhood_class'].astype(object)\n",
    "\n",
    "# presence of certain features\n",
    "df_original['Alley_present'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['Alley_present'].loc[df_original['Alley'] != 0] = 1\n",
    "\n",
    "df_original['Bsmt_present'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['Bsmt_present'].loc[df_original['BsmtQual'] != 0] = 1\n",
    "\n",
    "df_original['BsmtFinType1_present'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['BsmtFinType1_present'].loc[df_original['BsmtFinType1'] != 0] = 1\n",
    "\n",
    "df_original['BsmtFinType2_present'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['BsmtFinType2_present'].loc[df_original['BsmtFinType2'] != 0] = 1\n",
    "\n",
    "df_original['Fireplace_present'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['Fireplace_present'].loc[df_original['FireplaceQu'] != 0] = 1\n",
    "\n",
    "df_original['Garage_present'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['Garage_present'].loc[df_original['GarageQual'] != 0] = 1\n",
    "\n",
    "df_original['Fence_present'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['Fence_present'].loc[df_original['Fence'] != 0] = 1\n",
    "\n",
    "df_original['MiscFeature_present'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['MiscFeature_present'].loc[df_original['MiscFeature'] != 0] = 1\n",
    "\n",
    "\n",
    "#season\n",
    "df_original['Season'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['Season'] = df_original['MoSold'].map({'Jan':0,'Feb':0,'Mar':0,'Apr':0,'May':0,'Jun':0,'Jul':0,\n",
    "                                                   'Aug':1,'Sep':1,'Oct':0,'Nov':1,'Dec':1})\n",
    "df_original['Season'] = df_original['Season'].astype(object)\n",
    "\n",
    "\n",
    "#newer_dwelling\n",
    "df_original['Newer_dwelling'] = df_original['MSSubClass'].map({'S20':1,'S30':0,'S40':0,'S45':0,'S50':0,\n",
    "                                                               'S60':1,'S70':0,'S75':0,'S80':0,'S85':0,\n",
    "                                                               'S90':0,'S120':1,'S150':0,'S160':0,'S180':0,'S190':0})\n",
    "df_original['Newer_dwelling'] = df_original['Newer_dwelling'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the Quality and the Condition variables, Another variable was engineered for dividing them into good(1) or bad(0) quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_original['OverallQual_class'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['OverallQual_class'].loc[df_original['OverallQual'] > 5] = 1\n",
    "\n",
    "df_original['OverallCond_class'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['OverallCond_class'].loc[df_original['OverallCond'] > 5] = 1\n",
    "\n",
    "df_original['ExterQual_class'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['ExterQual_class'].loc[df_original['ExterQual'] > 3] = 1\n",
    "\n",
    "df_original['ExterCond_class'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['ExterCond_class'].loc[df_original['ExterCond'] > 3] = 1\n",
    "\n",
    "df_original['BsmtQual_class'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['BsmtQual_class'].loc[df_original['BsmtQual'] > 3] = 1\n",
    "\n",
    "df_original['BsmtCond_class'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['BsmtCond_class'].loc[df_original['BsmtCond'] > 3] = 1\n",
    "\n",
    "df_original['HeatingQC_class'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['HeatingQC_class'].loc[df_original['HeatingQC'] > 3] = 1\n",
    "\n",
    "df_original['KitchenQual_class'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['KitchenQual_class'].loc[df_original['KitchenQual'] > 3] = 1\n",
    "\n",
    "df_original['FireplaceQu_class'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['FireplaceQu_class'].loc[df_original['FireplaceQu'] > 3] = 1\n",
    "\n",
    "df_original['GarageQual_class'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['GarageQual_class'].loc[df_original['GarageQual'] > 3] = 1\n",
    "\n",
    "df_original['GarageCond_class'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['GarageCond_class'].loc[df_original['GarageCond'] > 3] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Modifying the variables related to garage a bit\n",
    "2. If the garage was built after the house was sold then the presence of garages is misleading. So all the variables related to garage will be set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_original['GarageType'].loc[df_original['Garage_Age'] < 0] = 0\n",
    "df_original['GarageFinish'].loc[df_original['Garage_Age'] < 0] = 0\n",
    "df_original['GarageCars'].loc[df_original['Garage_Age'] < 0] = 0\n",
    "df_original['GarageArea'].loc[df_original['Garage_Age'] < 0] = 0\n",
    "df_original['GarageQual'].loc[df_original['Garage_Age'] < 0] = 0\n",
    "df_original['GarageCond'].loc[df_original['Garage_Age'] < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Modifying the garage age and Remodel age a bit depending on whether the garage and remodelling was done after or before the selling of the house. Normally the presence of a garage and remodeling will lead to increase of the price of the house but if they were done after the house was sold then they bear no significance to the price of the house\n",
    "\n",
    "2. Similarly another variable remodel is introduced to denote whether remodelling was done or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_original['GarageBuiltAfter'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['GarageBuiltAfter'].loc[df_original['YearBuilt'] > df_original['GarageYrBlt']] = 1\n",
    "df_original['Garage_Age'].loc[df_original['Garage_Age'] < 0] = 0\n",
    "\n",
    "df_original['Remodel'] = np.zeros((df_original.shape[0],1))\n",
    "df_original['Remodel'].loc[df_original['YearBuilt'] > df_original['YearRemodAdd']] = 1\n",
    "df_original['Remodel_Age'].loc[df_original['Remodel_Age'] < 0] = 0\n",
    "df_original['Remodel_Age'].loc[df_original['YearRemodAdd'] == df_original['YearBuilt']] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the variables year of built, year of remodelling and year of building garage as all these informations have been captured in engineered variables like remodel and remodel_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_original = df_original.drop(['YearBuilt','YearRemodAdd','GarageYrBlt'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing the dataset into categorical and continuous variables for further operation on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont = []\n",
    "for col in df_original.columns.values:\n",
    "    if df_original[col].dtype != 'object':\n",
    "        cont.append(col)\n",
    "df_original_cont = df_original[cont]\n",
    "df_original_cat = df_original.drop(cont, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features : (2912, 37)\n",
      "Number of continuous features : (2912, 65)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of categorical features : \" + str(df_original_cat.shape))\n",
    "print(\"Number of continuous features : \" + str(df_original_cont.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of continuous variables is far greater than the number of categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dummies for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cat_dummies = pd.get_dummies(df_original_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the features with very less non zero values as they would not have much effect on any model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_zero = []\n",
    "for col in df_cat_dummies.columns.values:\n",
    "    col_Notzero = np.count_nonzero(df_cat_dummies[col])\n",
    "    if col_Notzero < 3:\n",
    "        cols_zero.append(col)\n",
    "        \n",
    "df_cat_dummies = df_cat_dummies.drop(cols_zero, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to find out which variables are correlated and we are going to remove some correlated variables from the continuous features. The threshold for correlation has been set at 0.8. The indexes of the columns to be removed will be stored in the j_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Correlation tells relation between two attributes.\n",
    "# Correlation requires continous data. Hence, ignore categorical data\n",
    "# Calculates pearson co-efficient for all combinations\n",
    "df_cont_corr = df_original_cont.corr()\n",
    "# Set the threshold to select only highly correlated attributes\n",
    "threshold = 0.8\n",
    "# List of pairs along with correlation above threshold\n",
    "corr_list = []\n",
    "# J_columns would contain the indexes of the variables that we are planning to drop\n",
    "j_columns = []\n",
    "#Search for the highly correlated pairs\n",
    "for i in range(0,df_original_cont.shape[1]):\n",
    "    if i not in np.ravel(j_columns):\n",
    "        for j in range(i+1,df_original_cont.shape[1]):\n",
    "            if (df_cont_corr.iloc[i,j] >= threshold and df_cont_corr.iloc[i,j] < 1) or (df_cont_corr.iloc[i,j] < 0 and df_cont_corr.iloc[i,j] <= -threshold):\n",
    "                corr_list.append([df_cont_corr.iloc[i,j],i,j]) #store correlation and columns index\n",
    "                j_columns.append([j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 53, 54, 55, 45, 46, 47, 58, 26, 59, 28, 48, 30, 32, 49])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_columns = np.ravel(j_columns)\n",
    "j_columns # indexes of columns to drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets print the correlation values for the correlated columns whose correlation is greater than 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 and 16 = 0.81\n",
      "4 and 53 = 0.81\n",
      "6 and 54 = 0.93\n",
      "7 and 55 = 0.88\n",
      "9 and 45 = 0.84\n",
      "9 and 46 = 0.85\n",
      "9 and 47 = 0.84\n",
      "14 and 58 = 0.91\n",
      "18 and 26 = 0.81\n",
      "25 and 59 = 0.90\n",
      "27 and 28 = 0.86\n",
      "27 and 48 = 0.90\n",
      "29 and 30 = 0.89\n",
      "31 and 32 = 0.95\n",
      "31 and 49 = 0.93\n"
     ]
    }
   ],
   "source": [
    "for v,i,j in corr_list:\n",
    "    print (\"%s and %s = %.2f\" % (i,j,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets store the names of the features to drop in the list features_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_to_drop = []\n",
    "for i in j_columns:\n",
    "    features_to_drop.append(df_original_cont.columns[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets display the names of the features that we are going to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2ndFlrSF',\n",
       " 'OverallCond_class',\n",
       " 'ExterQual_class',\n",
       " 'ExterCond_class',\n",
       " 'Bsmt_present',\n",
       " 'BsmtFinType1_present',\n",
       " 'BsmtFinType2_present',\n",
       " 'HeatingQC_class',\n",
       " 'TotRmsAbvGrd',\n",
       " 'KitchenQual_class',\n",
       " 'FireplaceQu',\n",
       " 'Fireplace_present',\n",
       " 'GarageArea',\n",
       " 'GarageCond',\n",
       " 'Garage_present']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to drop the features which are correlated and they are in the array features_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_original_cont = df_original_cont.drop(features_to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets join the continuous and categorical variables into a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2912, 239)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df_original_cont.join(df_cat_dummies)\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets store the continuous and categorical columns values in a list. We will need them later on\n",
    "continuous_columns = df_original_cont.columns.values\n",
    "categorical_columns = df_cat_dummies.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if all the missing values in the dataframe has been filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create the train and target values to fit the predictive algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df_new.iloc[:train.shape[0],:]\n",
    "y_train = target_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is a regression algorithm we are going to use regression algorithms:-  \n",
    "1. Ridge regression - It is an extension of linear regression. Along with finding the best fit line for regression, it also takes care of overfitting problem. It regularizes the square of the coefficients.\n",
    "2. Lasso regression - It is similar to Lasso regression. It regularizes the absolute value of the coefficients.\n",
    "3. Elasticnet regression - It is again an extension of linear regression. It combines the regularization capabilities of Lasso and ridge regression  \n",
    "The metric that we are going to use for this particular problem is root mean squared error. For more information on root mean squared error, please visit this link https://en.wikipedia.org/wiki/Root-mean-square_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "scorer = make_scorer(mean_squared_error, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df_new.iloc[:train.shape[0],:]\n",
    "y_train = target_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>alpha</b> is the coefficient that is multiplied to square or absolute value of coefficients and this term is added to the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the most optimal value of alpha for Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter is {'alpha': 10}\n",
      "Root mean squared error is 0.113956734799\n"
     ]
    }
   ],
   "source": [
    "param = {'alpha':[0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 1, 10, 50]}\n",
    "model = Ridge()\n",
    "clf = GridSearchCV(model, param, scoring='neg_mean_squared_error', refit='True', n_jobs=1, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print (\"The best parameter is \" + str(clf.best_params_)) \n",
    "print (\"Root mean squared error is \" + str(np.sqrt(abs(clf.best_score_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the most optimal value of alpha for Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter is {'alpha': 0.001}\n",
      "Root mean squared error is 0.112804542528\n"
     ]
    }
   ],
   "source": [
    "param = {'alpha':[0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 1, 10, 50]}\n",
    "model = Lasso()\n",
    "clf = GridSearchCV(model, param, scoring='neg_mean_squared_error', refit='True', n_jobs=1, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print (\"The best parameter is \" + str(clf.best_params_)) \n",
    "print (\"Root mean squared error is \" + str(np.sqrt(abs(clf.best_score_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the most optimal value of alpha for Elastic Net Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter is {'alpha': 0.001, 'l1_ratio': 0.5}\n",
      "Root mean squared error is 0.111410838667\n"
     ]
    }
   ],
   "source": [
    "# For elastic net regerssion\n",
    "# if a * L1 + b * L2 is the regularizarin parameter in the cost fucntion where L1 is Lasso coefficients and L2 is Ridge coefficients\n",
    "# then alpha = a + b and l1_ratio = a / (a + b) in elastic net regression\n",
    "\n",
    "param = {'alpha':[0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 1, 10, 50],'l1_ratio':[0.2, 0.5, 0.8]}\n",
    "model = ElasticNet()\n",
    "clf = GridSearchCV(model, param, scoring='neg_mean_squared_error', refit='True', n_jobs=1, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print (\"The best parameter is \" + str(clf.best_params_)) \n",
    "print (\"Root mean squared error is \" + str(np.sqrt(abs(clf.best_score_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df_new.iloc[0:train.shape[0],:]\n",
    "y_train = target_log\n",
    "X_test = df_new.iloc[train.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets see if standardizing the continuous variables reduces the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Scaler standardizes features by removing the mean and scaling to unit variance. We perform standardization of the features by performing a fit_transform function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Abhishek.penumbra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_cat = X_train[categorical_columns]\n",
    "X_test_cat = X_test[categorical_columns]\n",
    "\n",
    "X_train_cont_scaler = X_train[continuous_columns]\n",
    "X_test_cont_scaler = X_test[continuous_columns]\n",
    "for col in X_train_cont_scaler.columns.values:\n",
    "    scaler = StandardScaler().fit(X_train_cont_scaler[col])\n",
    "    X_train_cont_scaler[col] = scaler.transform(X_train_cont_scaler[col].reshape(1,-1))[0]\n",
    "    X_test_cont_scaler[col] = scaler.transform(X_test_cont_scaler[col].reshape(1,-1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets join the continuous and categorical variables together to get the whole dataset again\n",
    "X_train_scaler = X_train_cont_scaler.join(X_train_cat)\n",
    "X_test_scaler = X_test_cont_scaler.join(X_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the most optimal value of alpha for <b>Ridge Regression</b> after normalizing the continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter is {'alpha': 10}\n",
      "Root mean squared error is 0.114010796491\n"
     ]
    }
   ],
   "source": [
    "param = {'alpha':[0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 1, 10, 50]}\n",
    "model = Ridge()\n",
    "clf = GridSearchCV(model, param, scoring='neg_mean_squared_error', refit='True', n_jobs=1, cv=5)\n",
    "clf.fit(X_train_scaler, y_train)\n",
    "print (\"The best parameter is \" + str(clf.best_params_)) \n",
    "print (\"Root mean squared error is \" + str(np.sqrt(abs(clf.best_score_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the most optimal value of alpha for Lasso Regression after normalizing the continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter is {'alpha': 0.001}\n",
      "Root mean squared error is 0.111810562195\n"
     ]
    }
   ],
   "source": [
    "param = {'alpha':[0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 1, 10, 50]}\n",
    "model = Lasso()\n",
    "clf = GridSearchCV(model, param, scoring='neg_mean_squared_error', refit='True', n_jobs=1, cv=5)\n",
    "clf.fit(X_train_scaler, y_train)\n",
    "print (\"The best parameter is \" + str(clf.best_params_)) \n",
    "print (\"Root mean squared error is \" + str(np.sqrt(abs(clf.best_score_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter is {'alpha': 0.001, 'l1_ratio': 0.5}\n",
      "Root mean squared error is 0.11105845109\n"
     ]
    }
   ],
   "source": [
    "param = {'alpha':[0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 1, 10, 50],'l1_ratio':[0.2, 0.5, 0.8]}\n",
    "model = ElasticNet()\n",
    "clf = GridSearchCV(model, param, scoring='neg_mean_squared_error', refit='True', n_jobs=1, cv=5)\n",
    "clf.fit(X_train_scaler, y_train)\n",
    "print (\"The best parameter is \" + str(clf.best_params_)) \n",
    "print (\"Root mean squared error is \" + str(np.sqrt(abs(clf.best_score_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After standardizing the continuous features, we could improve the scores of Lasso regression and Elastic net regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the final submission and we are going to take elastic net (It gave us our best cv score) as our model and the parameters have been taken from the cross validation operation done earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.001, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=10000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favoriteClf_EN = ElasticNet(alpha = 0.001, l1_ratio=0.5, max_iter=10000)\n",
    "favoriteClf_EN.fit(X_train_scaler,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets transform the predictions back to the real values by applying the exponential function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Predict_EN = np.expm1(favoriteClf_EN.predict(X_test_scaler))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets prepare the submission file for Elasticnet predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(Predict_EN, columns=[\"SalePrice\"])\n",
    "submission.insert(0, 'id', test_Ids)\n",
    "submission.reset_index()\n",
    "submission.to_csv('HousePricesReg.csv', index = False) #0.11895 leaderboard score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to try and see if random forest and xgboost does any better than the regression methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try out random forest first. For tree based modeling techniques we donot have to use thestandardized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the optimal value of trees for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter is {'n_estimators': 2000}\n",
      "Root mean squared error is 0.135889943061\n"
     ]
    }
   ],
   "source": [
    "param = {'n_estimators' : [500,1000,2000,3000]} # the number of treesof the random forests\n",
    "model = RandomForestRegressor(random_state=0) # fixing the random state for reproducibility\n",
    "clf = GridSearchCV(model, param, scoring='neg_mean_squared_error', refit='True', n_jobs=1, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print (\"The best parameter is \" + str(clf.best_params_)) \n",
    "print (\"Root mean squared error is \" + str(np.sqrt(abs(clf.best_score_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using random forest we are going to predict the house prices and store it in another submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Predict_RFR = np.expm1(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets prepare the submission file for Random Forest Regression predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(Predict_RFR, columns=[\"SalePrice\"])\n",
    "submission.insert(0, 'id', test_Ids)\n",
    "submission.reset_index()\n",
    "submission.to_csv('HousePricesRFR.csv', index = False) # 0.14548"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try xgboost now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to select number of trees as 2500, number of features as 0.8, maximum depth as 4 and subsample as 0.8 and see if xgboost can give us a mindblowing performance. Since Xgboost is relatively computationally expensive when number of trees is in the range of 5000s, so we just selected parameter values based on our discretion. We are not going to run gridsearch on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.114374189676\n"
     ]
    }
   ],
   "source": [
    "model_Xgb = xgb.XGBRegressor(colsample_bytree=0.8, gamma=0.0,learning_rate=0.01,max_depth=4,\n",
    "                             min_child_weight=4,n_estimators=2500,reg_alpha=0.9,reg_lambda=0.6,\n",
    "                             subsample=0.8,seed=42,silent=0)\n",
    "Score_Xgb_entry = np.sqrt(-cross_val_score(model_Xgb, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = 5)).mean()\n",
    "print(Score_Xgb_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using xgboost we are going to predict the house prices and store it in another submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0.0, learning_rate=0.01, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=4, missing=None, n_estimators=2500, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0.9, reg_lambda=0.6,\n",
       "       scale_pos_weight=1, seed=42, silent=0, subsample=0.8)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Predict_xgb = np.expm1(model_Xgb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(Predict_xgb, columns=[\"SalePrice\"])\n",
    "submission.insert(0, 'id', test_Ids)\n",
    "submission.reset_index()\n",
    "submission.to_csv('HousePricesXGB.csv', index = False) #0.12310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HousePricesRFR = pd.read_csv(\"HousePricesRFR.csv\")\n",
    "HousePricesXGB = pd.read_csv(\"HousePricesXGB.csv\")\n",
    "HousePricesReg = pd.read_csv(\"HousePricesReg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use some learning model to see if we can get a better score. For deep learning we have to use the standardized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras # importing keras\n",
    "from keras.models import Sequential # importing the type of model that we are gong to use\n",
    "from keras.layers import Dense, Activation # importing the densely connected neural netwok layer, activation is for introducing non liearity to the output\n",
    "from keras import optimizers # importing the optimizers to modify the weights later on\n",
    "from keras.wrappers.scikit_learn import KerasRegressor # importing the regressor of keras\n",
    "from sklearn.model_selection import KFold, cross_val_score # to find the local cv score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model(): # defining the architecture of the NN \n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_shape=(X_train.shape[1],), init = 'truncated_normal', activation = 'relu')) # first hidden layer\n",
    "    model.add(Dense(100, init = 'normal', activation = 'relu')) # second hidden layer\n",
    "    model.add(Dense(50, init = 'normal', activation = 'sigmoid')) # third hidden layer\n",
    "    model.add(Dense(1)) # output layer\n",
    "    op = optimizers.sgd(lr=0.01) # optimizer \n",
    "    model.compile(loss='mean_squared_error', optimizer=op) # configuration of the learning process\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# fix the number of epochs and the batch size\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 0.16 (0.01) MSE\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, random_state=seed)\n",
    "results = cross_val_score(estimator, X_train_scaler.values, y_train.values, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (np.sqrt(results).mean(), np.sqrt(results).std())) # printing the local cv score for kerass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The local cv score for <b>keras</b> is quite high compared to the linear regression methods. One reason can be that it is not getting enough data to learn properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final submission we are going to use an ensemble model which will have a weightage of 0.05 for random forest, 0.3 for xgboost and 0.65 for Elastic net regression. The weights are completely based on our own discretion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HousePrices = 0.1 * HousePricesRFR + 0.2 * HousePricesXGB + 0.7 * HousePricesReg # Producing an ensemble model\n",
    "# This model is giving a public leaderboard score of 0.11861"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(HousePrices, columns=[\"SalePrice\"])\n",
    "submission.insert(0, 'id', test_Ids)\n",
    "submission.reset_index()\n",
    "submission.to_csv('HousePricesSubmission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
